@article{Brooksbank2014,
author = {Brooksbank, Cath and Schneider, Maria Victoria and Radivojac, Predrag and Lewitter, Fran and Welch, Lonnie and Gaeta, Bruno and Schwartz, Russell},
doi = {10.1371/journal.pcbi.1003496},
journal = {PLoS Computational Biology},
number = {3},
pages = {e1003496},
title = {{Bioinformatics Curriculum Guidelines: Toward a Definition of Core Competencies}},
volume = {10},
year = {2014}
}
@article{Buneman2001,
author = {Buneman, Peter and Khanna, Sanjeev and Tan, Wang-Chiew and Chiew, Wang -},
journal = {Lecture Notes in Computer Science},
number = {January},
pages = {316--330},
title = {{Why and Where: A Characterization of Data Provenance}},
url = {http://homepages.inf.ed.ac.uk/opb/papers/ICDT2001.pdf},
volume = {1973},
year = {2001}
}
@article{Cock2009,
author = {Cock, Peter J.A. and Antao, Tiago and Chang, Jeffrey T. and Chapman, Brad A. and Cox, Cymon J. and Dalke, Andrew and Friedberg, Iddo and Hamelryck, Thomas and Kauff, Frank and Wilczynski, Bartek and {De Hoon}, Michiel J.L.},
doi = {10.1093/bioinformatics/btp163},
issn = {13674803},
journal = {Bioinformatics},
title = {{Biopython: Freely available Python tools for computational molecular biology and bioinformatics}},
year = {2009}
}
@article{DePaula2013,
abstract = {In this work, we used the PROV-DM model to manage data provenance in workflows of genome projects. This provenance model allows the storage of details of one workflow execution, e.g., raw and produced data and computational tools, their versions and parameters. Using this model, biologists can access details of one particular execution of a workflow, compare results produced by different executions, and plan new experiments more efficiently. In addition to this, a provenance simulator was created, which facilitates the inclusion of provenance data of one genome project workflow execution. Finally, we discuss one case study, which aims to identify genes involved in specific metabolic pathways of Bacillus cereus, as well as to compare this isolate with other phylogenetic related bacteria from the Bacillus group. B. cereus is an extremophilic bacteria, collected in warm water in the Midwestern Region of Brazil, its DNA samples having been sequenced with an NGS machine.},
author = {de Paula, Renato and Holanda, Maristela and Gomes, Luciana S.A. and Lifschitz, Sergio and Walter, Maria Emilia M.T.},
doi = {10.1186/1471-2105-14-S11-S6},
issn = {14712105},
journal = {BMC bioinformatics},
number = {Suppl 11},
pages = {S6},
publisher = {BioMed Central},
title = {{Provenance in bioinformatics workflows.}},
volume = {14 Suppl 1},
year = {2013}
}
@misc{Dong2020,
author = {Dong, Trung},
journal = {GitHub repository},
publisher = {GitHub},
title = {{PROV: A Python library for W3C Provenance Data Model}},
year = {2020}
}
@book{Groth2013,
author = {Groth, Paul and Moreau, Luc},
doi = {10.2200/S00528ED1V01Y201308WEB007},
editor = {Hendler, James and Ding, Ying},
isbn = {9781627052214},
pages = {131},
publisher = {Morgan {\&} Claypool},
title = {{An Introduction to PROV}},
year = {2013}
}
@article{Lakin2017,
abstract = {{\textcopyright} The Author(s) 2016. Antimicrobial resistance has become an imminent concern for public health. As methods for detection and characterization of antimicrobial resistance move from targeted culture and polymerase chain reaction to high throughput metagenomics, appropriate resources for the analysis of large-scale data are required. Currently, antimicrobial resistance databases are tailored to smaller-scale, functional profiling of genes using highly descriptive annotations. Such characteristics do not facilitate the analysis of large-scale, ecological sequence datasets such as those produced with the use of metagenomics for surveillance. In order to overcome these limitations, we present MEGARes (https://megares.meglab.org), a hand-curated antimicrobial resistance database and annotation structure that provides a foundation for the development of high throughput acyclical classifiers and hierarchical statistical analysis of big data. MEGARes can be browsed as a stand-alone resource through the website or can be easily integrated into sequence analysis pipelines through download. Also via the website, we provide documentation for AmrPlusPlus, a user-friendly Galaxy pipeline for the analysis of high throughput sequencing data that is pre-packaged for use with the MEGARes database.},
author = {Lakin, Steven M. and Dean, Chris and Noyes, Noelle R. and Dettenwanger, Adam and Ross, Anne Spencer and Doster, Enrique and Rovira, Pablo and Abdo, Zaid and Jones, Kenneth L. and Ruiz, Jaime and Belk, Keith E. and Morley, Paul S. and Boucher, Christina},
doi = {10.1093/nar/gkw1009},
issn = {13624962},
journal = {Nucleic Acids Research},
month = {jan},
number = {D1},
pages = {D574--D580},
publisher = {Oxford University Press},
title = {{MEGARes: An antimicrobial resistance database for high throughput sequencing}},
volume = {45},
year = {2017}
}
@article{Markowetz2017,
author = {Markowetz, Florian},
doi = {10.1371/journal.pbio.2002050},
issn = {15457885},
journal = {PLoS Biology},
number = {3},
pages = {4--7},
pmid = {28278152},
title = {{All biology is computational biology}},
volume = {15},
year = {2017}
}
@article{Mattoso2010,
author = {Mattoso, Marta and Werner, Claudia and Travassos, Guilherme Horta and Braganholo, Vanessa and Ogasawara, Eduardo and Oliveira, Daniel De and Cruz, Sergio Manuel Serra Da and Martinho, Wallace and Murta, Leonardo},
doi = {10.1504/ijbpim.2010.033176},
issn = {1741-8763},
journal = {International Journal of Business Process Integration and Management},
number = {1},
pages = {79},
title = {{Towards supporting the life cycle of large scale scientific experiments}},
volume = {5},
year = {2010}
}
@article{Jackson2020,
author = {Jackson, Michael J and Wallace, Edward and Kavoussanakis, Kostas},
journal = {bioRxiv},
pages = {2020.08.04.236208},
title = {{Using rapid prototyping to choose a bioinformatics workflow management system}},
url = {https://doi.org/10.1101/2020.08.04.236208},
year = {2020}
}
@article{Kanwal2017,
abstract = {Background: Computational bioinformatics workflows are extensively used to analyse genomics data, with different approaches available to support implementation and execution of these workflows. Reproducibility is one of the core principles for any scientific workflow and remains a challenge, which is not fully addressed. This is due to incomplete understanding of reproducibility requirements and assumptions of workflow definition approaches. Provenance information should be tracked and used to capture all these requirements supporting reusability of existing workflows. Results: We have implemented a complex but widely deployed bioinformatics workflow using three representative approaches to workflow definition and execution. Through implementation, we identified assumptions implicit in these approaches that ultimately produce insufficient documentation of workflow requirements resulting in failed execution of the workflow. This study proposes a set of recommendations that aims to mitigate these assumptions and guides the scientific community to accomplish reproducible science, hence addressing reproducibility crisis. Conclusions: Reproducing, adapting or even repeating a bioinformatics workflow in any environment requires substantial technical knowledge of the workflow execution environment, resolving analysis assumptions and rigorous compliance with reproducibility requirements. Towards these goals, we propose conclusive recommendations that along with an explicit declaration of workflow specification would result in enhanced reproducibility of computational genomic analyses.},
author = {Kanwal, Sehrish and Khan, Farah Zaib and Lonie, Andrew and Sinnott, Richard O.},
doi = {10.1186/s12859-017-1747-0},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Common Workflow Language (CWL),Cpipe,Galaxy,Provenance,Reproducibility,Workflow},
month = {jul},
number = {1},
pages = {337},
publisher = {BioMed Central Ltd.},
title = {{Investigating reproducibility and tracking provenance - A genomic workflow case study}},
url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1747-0},
volume = {18},
year = {2017}
}
@article{Khan2019,
abstract = {Background: The automation of data analysis in the form of scientific workflows has become a widely adopted practice in many fields of research. Computationally driven data-intensive experiments using workflows enable automation, scaling, adaptation, and provenance support. However, there are still several challenges associated with the effective sharing, publication, and reproducibility of such workflows due to the incomplete capture of provenance and lack of interoperability between different technical (software) platforms. Results: Based on best-practice recommendations identified from the literature on workflow design, sharing, and publishing, we define a hierarchical provenance framework to achieve uniformity in provenance and support comprehensive and fully re-executable workflows equipped with domain-specific information. To realize this framework, we present CWLProv, a standard-based format to represent any workflow-based computational analysis to produce workflow output artefacts that satisfy the various levels of provenance. We use open source community-driven standards, interoperable workflow definitions in Common Workflow Language (CWL), structured provenance representation using the W3C PROV model, and resource aggregation and sharing as workflow-centric research objects generated along with the final outputs of a given workflow enactment. We demonstrate the utility of this approach through a practical implementation of CWLProv and evaluation using real-life genomic workflows developed by independent groups. Conclusions: The underlying principles of the standards utilized by CWLProv enable semantically rich and executable research objects that capture computational workflows with retrospective provenance such that any platform supporting CWL will be able to understand the analysis, reuse the methods for partial reruns, or reproduce the analysis to validate the published findings.},
author = {Khan, Farah Zaib and Soiland-Reyes, Stian and Sinnott, Richard O. and Lonie, Andrew and Goble, Carole and Crusoe, Michael R.},
doi = {10.1093/gigascience/giz095},
issn = {2047217X},
journal = {GigaScience},
keywords = {BagIt,CWL,Common Workflow Language,RO,Research Object,containers,interoperability,provenance,scientific workflows},
number = {11},
pmid = {31675414},
title = {{Sharing interoperable workflow provenance: A review of best practices and their practical application in CWLProv}},
volume = {8},
year = {2019}
}
@inproceedings{de2010scicumulus,
author = {de Oliveira, Daniel and Ogasawara, Eduardo and Bai{\~{a}}o, Fernanda and Mattoso, Marta},
booktitle = {2010 IEEE 3rd International Conference on Cloud Computing},
organization = {IEEE},
pages = {378--385},
title = {{Scicumulus: A lightweight cloud middleware to explore many task computing paradigm in scientific workflows}},
year = {2010}
}

@article{Pasquier2017,
author = {Pasquier, Thomas and Lau, Matthew K. and Trisovic, Ana and Boose, Emery R. and Couturier, Ben and Crosas, Merc{\`{e}} and Ellison, Aaron M. and Gibson, Valerie and Jones, Chris R. and Seltzer, Margo},
doi = {10.1038/sdata.2017.114},
issn = {20524463},
journal = {Scientific Data},
pages = {1--5},
title = {{If these data could talk}},
volume = {4},
year = {2017}
}
@inproceedings{ragan2014jupyter,
author = {Ragan-Kelley, Min and Perez, F and Granger, B and Kluyver, T and Ivanov, P and Frederic, J and Bussonnier, M},
booktitle = {AGU Fall Meeting Abstracts},
title = {{The Jupyter/IPython architecture: a unified view of computational research, from interactive exploration to communication and publication.}},
year = {2014}
}

@article{Silva2018,
abstract = {We present DfAnalyzer, a tool that enables monitoring, debugging, steering, and analysis of dataflows while being generated by scientific applications. It works by capturing strategic domain data, registering provenance and execution data to enable queries at runtime. DfAnalyzer provides lightweight dataflow monitoring components to be invoked by high performance applications. It can be plugged in scientific code scripts, or Spark applications, in the same way users already plug visualization library components. During this demo, we will show how DfAnalyzer captures the dataflow, provenance, as well as how it provides runtime data analyses of applications. We will also encourage attendees to use DfAnalyzer for their own applications.},
author = {Silva, V{\'{i}}tor and de Oliveira, Daniel and Valduriez, Patrick and Mattoso, Marta},
doi = {10.14778/3229863.3236265},
number = {12},
pages = {2082--2085},
title = {{DfAnalyzer: Runtime Dataflow Analysis of Scientific Applications using Provenance}},
url = {https://doi.org/10.14778/3229863.3236265},
volume = {11},
year = {2018}
}
@article{Stevens2007,
author = {Stevens, Robert and Zhao, Jun and Goble, Carole},
doi = {10.1093/bib/bbm015},
issn = {14675463},
journal = {Briefings in Bioinformatics},
keywords = {Data derivation,In Silico experiments,Provenance,Validation and verification of results,Workflow},
number = {3},
pages = {183--194},
title = {{Using provenance to manage knowledge of In Silico experiments}},
volume = {8},
year = {2007}
}
@article{wilson2017good,
author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K},
journal = {PLOS Computational Biology},
number = {6},
doi = {10.1371/journal.pcbi.1005510},
pages = {e1005510},
publisher = {Public Library of Science},
title = {{Good enough practices in scientific computing}},
volume = {13},
year = {2017}
}

